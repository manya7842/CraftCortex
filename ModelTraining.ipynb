{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70d102d-afaa-4b96-8443-36c054685454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-image file: camel-18-min.webp\n",
      "Skipping non-image file: cd2741bc7f6b48558d807f352bbd6626.webp\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\animals\\rabbit\\10528.jpg\n",
      "Skipping non-image file: duplicate_0_il_570xN.1751489813_n5e4.webp\n",
      "Skipping non-image file: s-l1200.webp\n",
      "Skipping non-image file: grid_0_640_N.webp\n",
      "Skipping non-image file: HummingBird-Featured-Image.webp\n",
      "Skipping non-image file: hummingbird.webp\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\birds\\owl\\6901.jpg\n",
      "Skipping non-image file: origami-stegosaurus (1).webp\n",
      "Skipping non-image file: origami-stegosaurus.webp\n",
      "Skipping non-image file: origami-tuojiangosaurus.webp\n",
      "Skipping non-image file: stegosaurus (1).webp\n",
      "Skipping non-image file: Stegosaurus.webp\n",
      "Skipping non-image file: vrklSe7_d.webp\n",
      "Skipping non-image file: 6426a903d0f1d5d806f02703e4179f4049a7ab21_2000x2000.webp\n",
      "Skipping non-image file: scorpion-snake-min.webp\n",
      "Skipping non-image file: Scorpions.webp\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14849.jpg\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14850.jpg\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14851.jpg\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14856.jpg\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14858.jpg\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14859.jpg\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14863.jpg\n",
      "Warning: Unable to read image at path: C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami\\objects\\mask\\14864.jpg\n",
      "Skipping non-image file: Downloads - Shortcut.lnk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 128, 128  # Set the desired image dimensions\n",
    "\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for category in os.listdir(directory):\n",
    "        category_path = os.path.join(directory, category)\n",
    "\n",
    "        # Skip the unclassified folder\n",
    "        if category == 'unclassified':\n",
    "            continue\n",
    "\n",
    "        # Iterate over each label folder within the category\n",
    "        for label in os.listdir(category_path):\n",
    "            label_path = os.path.join(category_path, label)\n",
    "            \n",
    "            for file in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, file)\n",
    "                \n",
    "                # Ensure only image files are processed\n",
    "                if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    print(f\"Skipping non-image file: {file}\")\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                # Check if the image was read correctly\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Unable to read image at path: {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                images.append(img)\n",
    "                labels.append(label)  # Using the specific label (e.g., \"cat\") as the label\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Path to your dataset\n",
    "data_path = r'C:\\Users\\KIIT0001\\Desktop\\ml projects\\unzipped_origami'\n",
    "images, labels = load_images(data_path)\n",
    "\n",
    "# Normalize images\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c9aafa-0c82-4cff-9f99-9cfdd47edc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)  # Convert labels to numeric\n",
    "num_classes = len(label_encoder.classes_)        # Count unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f9abd7-16a9-430d-90e6-305f2eaf9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c170ca9c-a9a9-43b1-bff5-4a2765e01a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, encoded_labels, test_size=0.2, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a9bc28-91ef-42eb-b0e6-088e347f4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit generator to the training data\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4676419a-181b-4f9d-90c3-cc05b84bca10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT0001\\AppData\\Local\\Temp\\ipykernel_17316\\3707379827.py:22: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT0001\\AppData\\Local\\Temp\\ipykernel_17316\\3707379827.py:22: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    X_train, y_train,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Wrap generator with tf.data.Dataset.from_generator\n",
    "def train_gen():\n",
    "    for x, y in train_generator:\n",
    "        yield x, y\n",
    "\n",
    "# Define output types and shapes explicitly\n",
    "output_types = (tf.float32, tf.int64)\n",
    "output_shapes = (\n",
    "    tf.TensorShape([None, IMG_HEIGHT, IMG_WIDTH, 3]),  # Batch of images\n",
    "    tf.TensorShape([None])                              # Batch of labels\n",
    ")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    train_gen,\n",
    "    output_types=output_types,\n",
    "    output_shapes=output_shapes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a126928-22b8-4788-b0ef-e7b193777169",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3e05b6-2698-49a4-b80a-7f525ecf6627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.0237 - loss: 6.8763\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02732, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 554ms/step - accuracy: 0.0238 - loss: 6.8762 - val_accuracy: 0.0273 - val_loss: 6.5761 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - accuracy: 0.0563 - loss: 6.3931\n",
      "Epoch 2: val_accuracy improved from 0.02732 to 0.09071, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 541ms/step - accuracy: 0.0563 - loss: 6.3928 - val_accuracy: 0.0907 - val_loss: 6.1652 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.1118 - loss: 5.9016\n",
      "Epoch 3: val_accuracy improved from 0.09071 to 0.18251, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 528ms/step - accuracy: 0.1119 - loss: 5.9012 - val_accuracy: 0.1825 - val_loss: 5.5960 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.1599 - loss: 5.5252\n",
      "Epoch 4: val_accuracy improved from 0.18251 to 0.23169, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 529ms/step - accuracy: 0.1599 - loss: 5.5249 - val_accuracy: 0.2317 - val_loss: 5.2247 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.2162 - loss: 5.1023\n",
      "Epoch 5: val_accuracy improved from 0.23169 to 0.31148, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 531ms/step - accuracy: 0.2162 - loss: 5.1016 - val_accuracy: 0.3115 - val_loss: 4.6904 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.2518 - loss: 4.6581\n",
      "Epoch 6: val_accuracy improved from 0.31148 to 0.38251, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 541ms/step - accuracy: 0.2518 - loss: 4.6578 - val_accuracy: 0.3825 - val_loss: 4.3942 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - accuracy: 0.3140 - loss: 4.2105\n",
      "Epoch 7: val_accuracy improved from 0.38251 to 0.42951, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 532ms/step - accuracy: 0.3140 - loss: 4.2102 - val_accuracy: 0.4295 - val_loss: 4.1055 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.3488 - loss: 3.7914\n",
      "Epoch 8: val_accuracy improved from 0.42951 to 0.43279, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 535ms/step - accuracy: 0.3488 - loss: 3.7917 - val_accuracy: 0.4328 - val_loss: 4.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.3846 - loss: 3.7007\n",
      "Epoch 9: val_accuracy improved from 0.43279 to 0.49836, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 509ms/step - accuracy: 0.3847 - loss: 3.7000 - val_accuracy: 0.4984 - val_loss: 3.6139 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.4493 - loss: 3.3086\n",
      "Epoch 10: val_accuracy improved from 0.49836 to 0.53661, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 535ms/step - accuracy: 0.4494 - loss: 3.3084 - val_accuracy: 0.5366 - val_loss: 3.4572 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.4788 - loss: 3.0487\n",
      "Epoch 11: val_accuracy improved from 0.53661 to 0.54317, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 511ms/step - accuracy: 0.4788 - loss: 3.0489 - val_accuracy: 0.5432 - val_loss: 3.3776 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 0.5023 - loss: 3.0313\n",
      "Epoch 12: val_accuracy improved from 0.54317 to 0.55738, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 510ms/step - accuracy: 0.5024 - loss: 3.0308 - val_accuracy: 0.5574 - val_loss: 3.2052 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.5475 - loss: 2.7748\n",
      "Epoch 13: val_accuracy improved from 0.55738 to 0.58798, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 574ms/step - accuracy: 0.5475 - loss: 2.7747 - val_accuracy: 0.5880 - val_loss: 3.1286 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.5588 - loss: 2.6612\n",
      "Epoch 14: val_accuracy improved from 0.58798 to 0.59344, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 549ms/step - accuracy: 0.5589 - loss: 2.6610 - val_accuracy: 0.5934 - val_loss: 2.9806 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.5878 - loss: 2.5392\n",
      "Epoch 15: val_accuracy did not improve from 0.59344\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 527ms/step - accuracy: 0.5878 - loss: 2.5390 - val_accuracy: 0.5923 - val_loss: 2.9379 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.6253 - loss: 2.3298\n",
      "Epoch 16: val_accuracy improved from 0.59344 to 0.64481, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 536ms/step - accuracy: 0.6253 - loss: 2.3298 - val_accuracy: 0.6448 - val_loss: 2.7099 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.6240 - loss: 2.3167\n",
      "Epoch 17: val_accuracy did not improve from 0.64481\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 513ms/step - accuracy: 0.6240 - loss: 2.3165 - val_accuracy: 0.6208 - val_loss: 2.7224 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.6624 - loss: 2.0928\n",
      "Epoch 18: val_accuracy improved from 0.64481 to 0.64809, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 531ms/step - accuracy: 0.6624 - loss: 2.0927 - val_accuracy: 0.6481 - val_loss: 2.6545 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.6856 - loss: 2.0575\n",
      "Epoch 19: val_accuracy did not improve from 0.64809\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 517ms/step - accuracy: 0.6856 - loss: 2.0572 - val_accuracy: 0.6208 - val_loss: 2.6520 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.7096 - loss: 1.8917\n",
      "Epoch 20: val_accuracy improved from 0.64809 to 0.65355, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 545ms/step - accuracy: 0.7096 - loss: 1.8916 - val_accuracy: 0.6536 - val_loss: 2.5279 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.7409 - loss: 1.7663\n",
      "Epoch 21: val_accuracy improved from 0.65355 to 0.65902, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 544ms/step - accuracy: 0.7409 - loss: 1.7664 - val_accuracy: 0.6590 - val_loss: 2.4090 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.7261 - loss: 1.7596\n",
      "Epoch 22: val_accuracy did not improve from 0.65902\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 549ms/step - accuracy: 0.7261 - loss: 1.7594 - val_accuracy: 0.6361 - val_loss: 2.4380 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.7175 - loss: 1.7254\n",
      "Epoch 23: val_accuracy improved from 0.65902 to 0.66339, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 570ms/step - accuracy: 0.7176 - loss: 1.7251 - val_accuracy: 0.6634 - val_loss: 2.3992 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.7710 - loss: 1.5344\n",
      "Epoch 24: val_accuracy improved from 0.66339 to 0.67869, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 556ms/step - accuracy: 0.7710 - loss: 1.5344 - val_accuracy: 0.6787 - val_loss: 2.2590 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.7789 - loss: 1.4599\n",
      "Epoch 25: val_accuracy improved from 0.67869 to 0.69508, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 573ms/step - accuracy: 0.7790 - loss: 1.4598 - val_accuracy: 0.6951 - val_loss: 2.1264 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.7656 - loss: 1.4147\n",
      "Epoch 26: val_accuracy did not improve from 0.69508\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 584ms/step - accuracy: 0.7657 - loss: 1.4147 - val_accuracy: 0.6601 - val_loss: 2.2456 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.7849 - loss: 1.4398\n",
      "Epoch 27: val_accuracy did not improve from 0.69508\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 580ms/step - accuracy: 0.7849 - loss: 1.4396 - val_accuracy: 0.6798 - val_loss: 2.0832 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - accuracy: 0.7955 - loss: 1.3433\n",
      "Epoch 28: val_accuracy did not improve from 0.69508\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 584ms/step - accuracy: 0.7955 - loss: 1.3433 - val_accuracy: 0.6732 - val_loss: 2.1100 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.8091 - loss: 1.2777\n",
      "Epoch 29: val_accuracy improved from 0.69508 to 0.69617, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 587ms/step - accuracy: 0.8091 - loss: 1.2776 - val_accuracy: 0.6962 - val_loss: 1.9773 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - accuracy: 0.8221 - loss: 1.1866\n",
      "Epoch 30: val_accuracy did not improve from 0.69617\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 585ms/step - accuracy: 0.8221 - loss: 1.1865 - val_accuracy: 0.6874 - val_loss: 1.9935 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.8453 - loss: 1.0988\n",
      "Epoch 31: val_accuracy did not improve from 0.69617\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 584ms/step - accuracy: 0.8452 - loss: 1.0988 - val_accuracy: 0.6863 - val_loss: 2.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - accuracy: 0.8339 - loss: 1.0735\n",
      "Epoch 32: val_accuracy improved from 0.69617 to 0.69836, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 593ms/step - accuracy: 0.8340 - loss: 1.0734 - val_accuracy: 0.6984 - val_loss: 1.9395 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - accuracy: 0.8559 - loss: 0.9972\n",
      "Epoch 33: val_accuracy did not improve from 0.69836\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 579ms/step - accuracy: 0.8559 - loss: 0.9973 - val_accuracy: 0.6907 - val_loss: 1.9116 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.8584 - loss: 0.9776\n",
      "Epoch 34: val_accuracy did not improve from 0.69836\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 540ms/step - accuracy: 0.8584 - loss: 0.9774 - val_accuracy: 0.6842 - val_loss: 1.8860 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.8829 - loss: 0.8855\n",
      "Epoch 35: val_accuracy did not improve from 0.69836\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 536ms/step - accuracy: 0.8829 - loss: 0.8854 - val_accuracy: 0.6754 - val_loss: 1.8967 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - accuracy: 0.8652 - loss: 0.8728\n",
      "Epoch 36: val_accuracy did not improve from 0.69836\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 555ms/step - accuracy: 0.8652 - loss: 0.8728 - val_accuracy: 0.6754 - val_loss: 1.8723 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.8857 - loss: 0.8120\n",
      "Epoch 37: val_accuracy did not improve from 0.69836\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 559ms/step - accuracy: 0.8857 - loss: 0.8120 - val_accuracy: 0.6929 - val_loss: 1.8421 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - accuracy: 0.8845 - loss: 0.7781\n",
      "Epoch 38: val_accuracy improved from 0.69836 to 0.71366, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 574ms/step - accuracy: 0.8846 - loss: 0.7780 - val_accuracy: 0.7137 - val_loss: 1.7295 - learning_rate: 5.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.8920 - loss: 0.7465\n",
      "Epoch 39: val_accuracy improved from 0.71366 to 0.73770, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 565ms/step - accuracy: 0.8920 - loss: 0.7464 - val_accuracy: 0.7377 - val_loss: 1.6309 - learning_rate: 5.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.9102 - loss: 0.6760\n",
      "Epoch 40: val_accuracy did not improve from 0.73770\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 566ms/step - accuracy: 0.9102 - loss: 0.6760 - val_accuracy: 0.7169 - val_loss: 1.6988 - learning_rate: 5.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.9115 - loss: 0.6770\n",
      "Epoch 41: val_accuracy did not improve from 0.73770\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 566ms/step - accuracy: 0.9115 - loss: 0.6769 - val_accuracy: 0.7290 - val_loss: 1.6538 - learning_rate: 5.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.9376 - loss: 0.6275\n",
      "Epoch 42: val_accuracy did not improve from 0.73770\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 563ms/step - accuracy: 0.9375 - loss: 0.6275 - val_accuracy: 0.7377 - val_loss: 1.5879 - learning_rate: 5.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.9285 - loss: 0.6350\n",
      "Epoch 43: val_accuracy improved from 0.73770 to 0.73989, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 575ms/step - accuracy: 0.9285 - loss: 0.6350 - val_accuracy: 0.7399 - val_loss: 1.5287 - learning_rate: 5.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.9316 - loss: 0.6073\n",
      "Epoch 44: val_accuracy did not improve from 0.73989\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 555ms/step - accuracy: 0.9316 - loss: 0.6073 - val_accuracy: 0.7322 - val_loss: 1.5395 - learning_rate: 5.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.9266 - loss: 0.5961\n",
      "Epoch 45: val_accuracy improved from 0.73989 to 0.74208, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 560ms/step - accuracy: 0.9266 - loss: 0.5961 - val_accuracy: 0.7421 - val_loss: 1.5284 - learning_rate: 5.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.9337 - loss: 0.5545\n",
      "Epoch 46: val_accuracy improved from 0.74208 to 0.74317, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 569ms/step - accuracy: 0.9337 - loss: 0.5545 - val_accuracy: 0.7432 - val_loss: 1.4948 - learning_rate: 5.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.9322 - loss: 0.5411\n",
      "Epoch 47: val_accuracy did not improve from 0.74317\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 556ms/step - accuracy: 0.9322 - loss: 0.5411 - val_accuracy: 0.7290 - val_loss: 1.5265 - learning_rate: 5.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.9356 - loss: 0.5192\n",
      "Epoch 48: val_accuracy did not improve from 0.74317\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 566ms/step - accuracy: 0.9356 - loss: 0.5191 - val_accuracy: 0.7333 - val_loss: 1.4983 - learning_rate: 5.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.9488 - loss: 0.4856\n",
      "Epoch 49: val_accuracy did not improve from 0.74317\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 565ms/step - accuracy: 0.9488 - loss: 0.4856 - val_accuracy: 0.7366 - val_loss: 1.4703 - learning_rate: 5.0000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.9453 - loss: 0.4919\n",
      "Epoch 50: val_accuracy did not improve from 0.74317\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 555ms/step - accuracy: 0.9453 - loss: 0.4918 - val_accuracy: 0.7279 - val_loss: 1.5237 - learning_rate: 5.0000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.9458 - loss: 0.4683\n",
      "Epoch 51: val_accuracy improved from 0.74317 to 0.74426, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 562ms/step - accuracy: 0.9458 - loss: 0.4683 - val_accuracy: 0.7443 - val_loss: 1.4777 - learning_rate: 5.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - accuracy: 0.9447 - loss: 0.4456\n",
      "Epoch 52: val_accuracy improved from 0.74426 to 0.75191, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 571ms/step - accuracy: 0.9447 - loss: 0.4456 - val_accuracy: 0.7519 - val_loss: 1.4489 - learning_rate: 5.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - accuracy: 0.9538 - loss: 0.4233\n",
      "Epoch 53: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 553ms/step - accuracy: 0.9538 - loss: 0.4233 - val_accuracy: 0.7322 - val_loss: 1.4563 - learning_rate: 5.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step - accuracy: 0.9485 - loss: 0.4351\n",
      "Epoch 54: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 572ms/step - accuracy: 0.9485 - loss: 0.4351 - val_accuracy: 0.7399 - val_loss: 1.4230 - learning_rate: 5.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.9505 - loss: 0.4112\n",
      "Epoch 55: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 580ms/step - accuracy: 0.9505 - loss: 0.4111 - val_accuracy: 0.7202 - val_loss: 1.4247 - learning_rate: 5.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9577 - loss: 0.3927\n",
      "Epoch 56: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 591ms/step - accuracy: 0.9577 - loss: 0.3927 - val_accuracy: 0.7344 - val_loss: 1.4365 - learning_rate: 5.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9603 - loss: 0.3813\n",
      "Epoch 57: val_accuracy did not improve from 0.75191\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 592ms/step - accuracy: 0.9603 - loss: 0.3813 - val_accuracy: 0.7224 - val_loss: 1.4744 - learning_rate: 5.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9567 - loss: 0.3652\n",
      "Epoch 58: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 585ms/step - accuracy: 0.9567 - loss: 0.3651 - val_accuracy: 0.7290 - val_loss: 1.4038 - learning_rate: 2.5000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9579 - loss: 0.3683\n",
      "Epoch 59: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 593ms/step - accuracy: 0.9579 - loss: 0.3683 - val_accuracy: 0.7311 - val_loss: 1.3701 - learning_rate: 2.5000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9650 - loss: 0.3567\n",
      "Epoch 60: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 592ms/step - accuracy: 0.9650 - loss: 0.3568 - val_accuracy: 0.7322 - val_loss: 1.3486 - learning_rate: 2.5000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - accuracy: 0.9616 - loss: 0.3422\n",
      "Epoch 61: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 588ms/step - accuracy: 0.9616 - loss: 0.3422 - val_accuracy: 0.7508 - val_loss: 1.3251 - learning_rate: 2.5000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9650 - loss: 0.3466\n",
      "Epoch 62: val_accuracy did not improve from 0.75191\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 591ms/step - accuracy: 0.9650 - loss: 0.3466 - val_accuracy: 0.7421 - val_loss: 1.3449 - learning_rate: 2.5000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9669 - loss: 0.3282\n",
      "Epoch 63: val_accuracy did not improve from 0.75191\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 589ms/step - accuracy: 0.9669 - loss: 0.3282 - val_accuracy: 0.7497 - val_loss: 1.3289 - learning_rate: 1.2500e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9652 - loss: 0.3394\n",
      "Epoch 64: val_accuracy improved from 0.75191 to 0.75410, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 595ms/step - accuracy: 0.9652 - loss: 0.3393 - val_accuracy: 0.7541 - val_loss: 1.3147 - learning_rate: 1.2500e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9696 - loss: 0.3197\n",
      "Epoch 65: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 587ms/step - accuracy: 0.9696 - loss: 0.3197 - val_accuracy: 0.7519 - val_loss: 1.2996 - learning_rate: 1.2500e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9691 - loss: 0.3259\n",
      "Epoch 66: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 591ms/step - accuracy: 0.9692 - loss: 0.3258 - val_accuracy: 0.7541 - val_loss: 1.3000 - learning_rate: 1.2500e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9772 - loss: 0.3036\n",
      "Epoch 67: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 589ms/step - accuracy: 0.9771 - loss: 0.3036 - val_accuracy: 0.7497 - val_loss: 1.3038 - learning_rate: 1.2500e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9683 - loss: 0.3282\n",
      "Epoch 68: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 590ms/step - accuracy: 0.9683 - loss: 0.3281 - val_accuracy: 0.7508 - val_loss: 1.2977 - learning_rate: 1.2500e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9759 - loss: 0.3082\n",
      "Epoch 69: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 590ms/step - accuracy: 0.9759 - loss: 0.3082 - val_accuracy: 0.7508 - val_loss: 1.2762 - learning_rate: 1.2500e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - accuracy: 0.9777 - loss: 0.2925\n",
      "Epoch 70: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 582ms/step - accuracy: 0.9777 - loss: 0.2925 - val_accuracy: 0.7508 - val_loss: 1.2732 - learning_rate: 6.2500e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9733 - loss: 0.3000\n",
      "Epoch 71: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 587ms/step - accuracy: 0.9733 - loss: 0.3000 - val_accuracy: 0.7497 - val_loss: 1.2753 - learning_rate: 6.2500e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - accuracy: 0.9685 - loss: 0.3060\n",
      "Epoch 72: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 583ms/step - accuracy: 0.9685 - loss: 0.3060 - val_accuracy: 0.7443 - val_loss: 1.2666 - learning_rate: 6.2500e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9732 - loss: 0.2894\n",
      "Epoch 73: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 595ms/step - accuracy: 0.9732 - loss: 0.2894 - val_accuracy: 0.7486 - val_loss: 1.2683 - learning_rate: 6.2500e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9716 - loss: 0.2973\n",
      "Epoch 74: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 589ms/step - accuracy: 0.9716 - loss: 0.2973 - val_accuracy: 0.7508 - val_loss: 1.2695 - learning_rate: 6.2500e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9746 - loss: 0.3028\n",
      "Epoch 75: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 590ms/step - accuracy: 0.9746 - loss: 0.3028 - val_accuracy: 0.7497 - val_loss: 1.2730 - learning_rate: 3.1250e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9784 - loss: 0.2834\n",
      "Epoch 76: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 592ms/step - accuracy: 0.9784 - loss: 0.2834 - val_accuracy: 0.7541 - val_loss: 1.2702 - learning_rate: 3.1250e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - accuracy: 0.9698 - loss: 0.3016\n",
      "Epoch 77: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 588ms/step - accuracy: 0.9698 - loss: 0.3015 - val_accuracy: 0.7486 - val_loss: 1.2726 - learning_rate: 3.1250e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9718 - loss: 0.2977\n",
      "Epoch 78: val_accuracy did not improve from 0.75410\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 589ms/step - accuracy: 0.9718 - loss: 0.2976 - val_accuracy: 0.7508 - val_loss: 1.2712 - learning_rate: 3.1250e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9775 - loss: 0.2845\n",
      "Epoch 79: val_accuracy improved from 0.75410 to 0.75628, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 594ms/step - accuracy: 0.9775 - loss: 0.2845 - val_accuracy: 0.7563 - val_loss: 1.2682 - learning_rate: 3.1250e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9804 - loss: 0.2813\n",
      "Epoch 80: val_accuracy improved from 0.75628 to 0.75847, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 595ms/step - accuracy: 0.9804 - loss: 0.2813 - val_accuracy: 0.7585 - val_loss: 1.2641 - learning_rate: 3.1250e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9769 - loss: 0.2826\n",
      "Epoch 81: val_accuracy did not improve from 0.75847\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 590ms/step - accuracy: 0.9769 - loss: 0.2826 - val_accuracy: 0.7563 - val_loss: 1.2638 - learning_rate: 3.1250e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9780 - loss: 0.2763\n",
      "Epoch 82: val_accuracy did not improve from 0.75847\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 591ms/step - accuracy: 0.9779 - loss: 0.2763 - val_accuracy: 0.7585 - val_loss: 1.2595 - learning_rate: 3.1250e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9737 - loss: 0.2922\n",
      "Epoch 83: val_accuracy did not improve from 0.75847\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 590ms/step - accuracy: 0.9737 - loss: 0.2922 - val_accuracy: 0.7530 - val_loss: 1.2619 - learning_rate: 3.1250e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - accuracy: 0.9825 - loss: 0.2786\n",
      "Epoch 84: val_accuracy did not improve from 0.75847\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 588ms/step - accuracy: 0.9825 - loss: 0.2786 - val_accuracy: 0.7552 - val_loss: 1.2597 - learning_rate: 3.1250e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - accuracy: 0.9759 - loss: 0.2850\n",
      "Epoch 85: val_accuracy improved from 0.75847 to 0.76175, saving model to CraftCortex.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 594ms/step - accuracy: 0.9759 - loss: 0.2849 - val_accuracy: 0.7617 - val_loss: 1.2560 - learning_rate: 3.1250e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.9712 - loss: 0.2805\n",
      "Epoch 86: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 585ms/step - accuracy: 0.9712 - loss: 0.2805 - val_accuracy: 0.7617 - val_loss: 1.2524 - learning_rate: 3.1250e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9800 - loss: 0.2659\n",
      "Epoch 87: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 590ms/step - accuracy: 0.9800 - loss: 0.2659 - val_accuracy: 0.7607 - val_loss: 1.2530 - learning_rate: 3.1250e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9774 - loss: 0.2812\n",
      "Epoch 88: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 589ms/step - accuracy: 0.9774 - loss: 0.2813 - val_accuracy: 0.7552 - val_loss: 1.2517 - learning_rate: 3.1250e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9758 - loss: 0.2727\n",
      "Epoch 89: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 587ms/step - accuracy: 0.9758 - loss: 0.2726 - val_accuracy: 0.7552 - val_loss: 1.2500 - learning_rate: 3.1250e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.9774 - loss: 0.2770\n",
      "Epoch 90: val_accuracy did not improve from 0.76175\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 559ms/step - accuracy: 0.9774 - loss: 0.2770 - val_accuracy: 0.7552 - val_loss: 1.2492 - learning_rate: 3.1250e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - accuracy: 0.9765 - loss: 0.2705\n",
      "Epoch 91: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 551ms/step - accuracy: 0.9765 - loss: 0.2705 - val_accuracy: 0.7563 - val_loss: 1.2482 - learning_rate: 1.5625e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.9798 - loss: 0.2692\n",
      "Epoch 92: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 545ms/step - accuracy: 0.9798 - loss: 0.2692 - val_accuracy: 0.7552 - val_loss: 1.2491 - learning_rate: 1.5625e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.9765 - loss: 0.2756\n",
      "Epoch 93: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 539ms/step - accuracy: 0.9765 - loss: 0.2756 - val_accuracy: 0.7552 - val_loss: 1.2478 - learning_rate: 1.5625e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.9811 - loss: 0.2657\n",
      "Epoch 94: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 538ms/step - accuracy: 0.9811 - loss: 0.2657 - val_accuracy: 0.7574 - val_loss: 1.2480 - learning_rate: 1.5625e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.9809 - loss: 0.2654\n",
      "Epoch 95: val_accuracy did not improve from 0.76175\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 539ms/step - accuracy: 0.9809 - loss: 0.2654 - val_accuracy: 0.7585 - val_loss: 1.2480 - learning_rate: 1.5625e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.9824 - loss: 0.2648\n",
      "Epoch 96: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 541ms/step - accuracy: 0.9824 - loss: 0.2647 - val_accuracy: 0.7596 - val_loss: 1.2471 - learning_rate: 1.0000e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - accuracy: 0.9793 - loss: 0.2719\n",
      "Epoch 97: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 554ms/step - accuracy: 0.9793 - loss: 0.2719 - val_accuracy: 0.7574 - val_loss: 1.2464 - learning_rate: 1.0000e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.9763 - loss: 0.2716\n",
      "Epoch 98: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 553ms/step - accuracy: 0.9763 - loss: 0.2716 - val_accuracy: 0.7596 - val_loss: 1.2457 - learning_rate: 1.0000e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.9787 - loss: 0.2675\n",
      "Epoch 99: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 557ms/step - accuracy: 0.9787 - loss: 0.2675 - val_accuracy: 0.7607 - val_loss: 1.2441 - learning_rate: 1.0000e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - accuracy: 0.9773 - loss: 0.2694\n",
      "Epoch 100: val_accuracy did not improve from 0.76175\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 551ms/step - accuracy: 0.9773 - loss: 0.2694 - val_accuracy: 0.7617 - val_loss: 1.2435 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define the base model\n",
    "#base_model = MobileNetV2(input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), include_top=False, weights='imagenet')\n",
    "base_model = MobileNetV2(input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),\n",
    "                           include_top=False,\n",
    "                           weights='imagenet')\n",
    "base_model.trainable = True  # Unfreeze the base model layers\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x= Dropout(0.5)(x)\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"CraftCortex.keras\",\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=228,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint, lr_scheduler, early_stopping],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f736ff29-5697-4ddd-b64f-693d79519007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.7502 - loss: 1.3005\n",
      "Test Accuracy: 76.17%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8500f34-50eb-49e3-9e3e-d474c3052592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b6d9cea-e028-4b21-b35b-4242fbacbb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"CraftCortex.h5\", include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fa7fc19-3694-4129-b08e-bd1a543b35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"CraftCortex.keras\", include_optimizer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
